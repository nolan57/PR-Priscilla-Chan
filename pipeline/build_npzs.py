#!/usr/bin/env python3
"""
Build DiffSinger training .npz dataset (supports external high-precision F0)
[Enhanced version] Includes strict frame-level consistency verification

Input:
- Dry vocal WAV files (44.1kHz)
- Corresponding TextGrid (containing "phones" tier)
- (Optional) External F0 files (generated by extract_perfect_f0.py, format: *.f0.npy)

Output:
- Standard DiffSinger .npz files, containing:
 - 'f0': [T] # fundamental frequency (Hz)
 - 'mel': [n_mel, T] # mel spectrogram
 - 'ph_seq': [N] # phoneme sequence
 - 'ph_dur': [N] # phoneme duration (frame count)
 - 'spk_id': 0 # speaker ID (set to 0 for single speaker)

F0 priority:
1. If {wav}.f0.npy exists ‚Üí use external F0
2. Otherwise ‚Üí use librosa.pyin extraction (fallback only)

Suggested directory structure:
dataset/
‚îú‚îÄ‚îÄ wav/        # dry vocals
‚îú‚îÄ‚îÄ textgrid/   # alignment results
‚îú‚îÄ‚îÄ f0/         # external F0 (optional)
‚îî‚îÄ‚îÄ npz/        # output directory
"""

import os
import numpy as np
import librosa
import torch
import torch.nn.functional as F
from librosa.filters import mel as librosa_mel_fn
from textgrid import TextGrid
from pathlib import Path
import argparse

# ====== Global configuration ======
SAMPLE_RATE = 44100
HOP_LENGTH = 512  # 10ms @ 44.1kHz
WIN_LENGTH = 2048
N_FFT = 2048
N_MELS = 128
FMIN = 40
FMAX = 16000


def dynamic_range_compression_torch(x, C=1, clip_val=1e-5):
    """Dynamic range compression function, consistent with the implementation in DiffSinger"""
    return torch.log(torch.clamp(x, min=clip_val) * C)


class STFT:
    """Simplified STFT class for mel spectrogram extraction, consistent with DiffSinger"""
    def __init__(self, sr=44100, n_mels=128, n_fft=2048, win_size=2048, hop_length=512, fmin=40, fmax=16000):
        self.target_sr = sr
        self.n_fft = n_fft
        self.win_size = win_size
        self.hop_length = hop_length
        self.fmin = fmin
        self.fmax = fmax

        # Create mel filter bank
        mel_basis = librosa_mel_fn(sr=sr, n_fft=n_fft, n_mels=n_mels, fmin=fmin, fmax=fmax)
        self.mel_basis = torch.from_numpy(mel_basis).float()

    def get_mel(self, y, center=False):
        # Ensure input is tensor
        if not isinstance(y, torch.Tensor):
            y = torch.from_numpy(y).float()  # Ensure it's float type
        else:
            y = y.float()

        # Add batch dimension
        y = y.unsqueeze(0) if y.dim() == 1 else y

        # Hann window
        window = torch.hann_window(self.win_size).to(y.device).float()

        # Reflection padding
        y = torch.nn.functional.pad(y.unsqueeze(1), (
            (self.win_size - self.hop_length) // 2,
            (self.win_size - self.hop_length + 1) // 2
        ), mode='reflect')
        y = y.squeeze(1)

        # STFT
        spec = torch.stft(
            y, self.n_fft, hop_length=self.hop_length,
            win_length=self.win_size, window=window,
            center=center, pad_mode='reflect',
            normalized=False, onesided=True, return_complex=True
        ).abs()

        # Ensure spec and mel_basis have consistent types
        spec = spec.float()

        # Apply mel filter bank
        spec = torch.matmul(self.mel_basis.to(spec.device).to(spec.dtype), spec)

        # Dynamic range compression
        spec = dynamic_range_compression_torch(spec)

        return spec.squeeze(0).numpy()

# Cantonese phoneme set (example, can be adjusted according to actual needs)
PHONEME_SET = {'sil', 'sp', 'br'}  # Special symbols


def load_textgrid_phones(textgrid_path):
    """Load phoneme sequence and boundaries (in seconds) from TextGrid"""
    tg = TextGrid.fromFile(textgrid_path)
    phones_tier = tg.getFirst("phones")
    if phones_tier is None:
        raise ValueError(f'Not found "phones" tier: {textgrid_path}')

    phones = []
    boundaries = [0.0]  # Start time
    for interval in phones_tier:
        mark = interval.mark.strip()
        if mark == "":
            mark = "sp"  # Mark silence segment as sp
        phones.append(mark)
        boundaries.append(interval.maxTime)
    return phones, np.array(boundaries)


def seconds_to_frames(time_sec, hop_length=HOP_LENGTH, sr=SAMPLE_RATE):
    """Convert time (seconds) to frame indices"""
    return np.round(time_sec * sr / hop_length).astype(int)


def align_phoneme_durations(phones, boundaries, total_frames):
    """
    Align phoneme boundaries to mel frames and calculate frames per phoneme.
    [Enhanced] Includes more robust frame count correction logic.
    """
    frame_boundaries = seconds_to_frames(boundaries)
    frame_boundaries = np.clip(frame_boundaries, 0, total_frames)
    frame_boundaries[-1] = total_frames  # Ensure end alignment
    ph_durs = np.diff(frame_boundaries)

    # Safety check 1: Avoid zero or negative durations
    if np.any(ph_durs <= 0):
        print(f"‚ö†Ô∏è  Found zero or negative duration phonemes, will correct to 1 frame")
        ph_durs = np.maximum(ph_durs, 1)

    # Safety check 2: Fix total frame count inconsistency
    current_sum = ph_durs.sum()
    if current_sum != total_frames:
        diff = total_frames - current_sum
        print(f"‚ö†Ô∏è  Phoneme duration sum ({current_sum}) does not match target frames ({total_frames}), difference: {diff}")

        # Simple strategy: Add difference to the last phoneme
        # More advanced strategy could distribute proportionally, but this method is simple and effective
        ph_durs[-1] += diff

        # Secondary check to ensure no new negatives are created
        if ph_durs[-1] <= 0:
            raise RuntimeError(
                f"Phoneme duration of last phoneme is still non-positive ({ph_durs[-1]}) after correction."
                "Please check TextGrid alignment quality."
            )
        print(f"    -> Difference distributed to the last phoneme.")

    return phones, ph_durs


def extract_external_f0(wav_path, f0_dir=None):
    """Try to load external F0 file ({f0_dir}/{basename}.f0.npy or {wav_dir}/{basename}.f0.npy)"""
    wav_path = Path(wav_path)
    basename = wav_path.stem
    
    # If f0_dir is specified, search in that directory
    if f0_dir:
        f0_dir = Path(f0_dir)
        f0_path = f0_dir / f"{basename}.f0.npy"
        print(f"[DEBUG] Attempting to load external F0: {f0_path}")
        if f0_path.exists():
            print(f"‚úÖ Loading external F0: {f0_path}")
            return np.load(str(f0_path))
    
    # Otherwise search in the same directory as the audio file
    f0_path = str(wav_path).replace('.wav', '.f0.npy')
    if os.path.exists(f0_path):
        print(f"‚úÖ Loading external F0: {f0_path}")
        return np.load(f0_path)
    
    print(f"‚ö†Ô∏è  External F0 not found, will use pyin extraction")
    return None


def extract_f0_pyin(y, sr=SAMPLE_RATE, hop_length=HOP_LENGTH):
    """Extract F0 using librosa.pyin (fallback option)"""
    f0,* _ = librosa.pyin(
        y, fmin=FMIN, fmax=FMAX, sr=sr, hop_length=hop_length, fill_na=0.0
    )
    return f0


def extract_mel_spectrogram(y, sr=SAMPLE_RATE):
    """Extract mel spectrogram, consistent with DiffSinger implementation"""
    # Create STFT object
    stft = STFT(sr=sr, n_mels=N_MELS, n_fft=N_FFT, win_size=WIN_LENGTH,
                hop_length=HOP_LENGTH, fmin=FMIN, fmax=FMAX)

    # Get mel spectrogram
    mel = stft.get_mel(y)

    return mel


def validate_and_clip_features(f0, mel, wav_name):
    """
    Ensure F0 and Mel frame counts are consistent, cropping/interpolating if necessary.
    [Enhanced] Provide more detailed logs.
    """
    mel_frames = mel.shape[1]
    f0_frames = len(f0)

    if f0_frames == mel_frames:
        return f0, mel

    print(f"‚ö†Ô∏è  {wav_name}: F0 ({f0_frames}) and Mel ({mel_frames}) frame counts are inconsistent")

    if abs(f0_frames - mel_frames) <= 2:
        # Small difference: Directly crop to shorter one
        min_len = min(f0_frames, mel_frames)
        f0 = f0[:min_len]
        mel = mel[:, :min_len]
        print(f" ‚Üí Cropped to {min_len} frames")
    else:
        # Large difference: Interpolate F0 to Mel length
        print(f" ‚Üí Interpolating F0 to {mel_frames} frames")
        x_old = np.linspace(0, 1, f0_frames)
        x_new = np.linspace(0, 1, mel_frames)
        f0_interp = np.interp(x_new, x_old, f0)
        f0 = f0_interp
        mel = mel

    return f0, mel


def build_single_npz(wav_path, textgrid_path, output_path, use_external_f0=True, f0_dir=None):
    """Build a single .npz file and perform final consistency verification"""
    print(f"\n--- Processing file: {Path(wav_path).name} ---")

        # 1. Load audio
    y, sr = librosa.load(wav_path, sr=SAMPLE_RATE, mono=True)
    print(f"Audio length: {len(y) / sr:.2f}s, samples: {len(y)}")

        # 2. Extract mel spectrogram
    mel = extract_mel_spectrogram(y, sr)
    total_frames = mel.shape[1]
    print(f"Mel spectrogram frames: {total_frames}")

        # 3. Extract F0
    if use_external_f0:
        f0 = extract_external_f0(wav_path, f0_dir)
    else:
        f0 = None

    if f0 is None:
        f0 = extract_f0_pyin(y, sr, HOP_LENGTH)
        print("Using pyin to extract F0")
    else:
        print("Using external F0")

        # 4. Align F0 with Mel
    f0, mel = validate_and_clip_features(f0, mel, Path(wav_path).name)
    aligned_frames = mel.shape[1]
    print(f"F0/Mel aligned frames: {aligned_frames}")

        # 5. Load and align phonemes
    phones, boundaries = load_textgrid_phones(textgrid_path)
    phones, ph_durs = align_phoneme_durations(phones, boundaries, aligned_frames)
    dur_sum = ph_durs.sum()
    print(f"Phoneme duration sum: {dur_sum}")

    # ==============================
    # [Critical] Final consistency hard check
    # ==============================
    assert aligned_frames == dur_sum, (
        f"\n‚ùå Fatal error: F0/Mel frame count ({aligned_frames}) "
        f"does not match phoneme duration sum ({dur_sum})!\n"
        "Please check:\n"
        "1. Whether TextGrid alignment is accurate\n"
        "2. Whether external F0 matches current audio\n"
        "3. Whether audio was unexpectedly truncated"
    )
    print("‚úÖ All feature frames passed final consistency verification!")

        # 6. Save .npz
    np.savez(
        output_path,
        f0=f0.astype(np.float32),
        mel=mel.astype(np.float32),
        ph_seq=np.array(phones),
        ph_dur=ph_durs.astype(np.int64),
        spk_id=np.array([0], dtype=np.int64)  # Single speaker
    )
    print(f"‚úÖ Saved successfully: {output_path}")


def main():
    parser = argparse.ArgumentParser(description="Build DiffSinger .npz dataset with external F0 support.")
    parser.add_argument("--wav_dir", required=True, help="Directory containing dry vocal WAV files")
    parser.add_argument("--textgrid_dir", required=True, help="Directory containing TextGrid files")
    parser.add_argument("--f0_dir", help="Directory containing external F0 files (optional, expects {basename}.f0.npy)")
    parser.add_argument("--output_dir", required=True, help="Output directory for .npz files")
    parser.add_argument("--use_external_f0", action="store_true",
                        help="Enable loading of external F0 (first checks --f0_dir if provided, then wav directory)")
    parser.add_argument("--speaker_id", type=int, default=0, help="Speaker ID (default: 0)")
    args = parser.parse_args()

    wav_dir = Path(args.wav_dir)
    tg_dir = Path(args.textgrid_dir)
    f0_dir = Path(args.f0_dir) if args.f0_dir else None
    out_dir = Path(args.output_dir)
    out_dir.mkdir(exist_ok=True)

    wav_files = sorted(wav_dir.glob("*.wav"))
    print(f"üîç Found {len(wav_files)} WAV files")

    success_count = 0
    for wav_path in wav_files:
        base_name = wav_path.stem
        tg_path = tg_dir / f"{base_name}.TextGrid"
        if not tg_path.exists():
            print(f"‚ùå Skip {base_name}: Corresponding TextGrid not found")
            continue

        output_path = out_dir / f"{base_name}.npz"
        try:
            build_single_npz(
                wav_path=str(wav_path),
                textgrid_path=str(tg_path),
                output_path=str(output_path),
                use_external_f0=args.use_external_f0,
                f0_dir=f0_dir
            )
            success_count += 1
        except Exception as e:
            print(f"‚ùå Error processing {base_name}: {e}")

    print(f"\nüéâ Completed! Successfully processed {success_count}/{len(wav_files)} files")
    print(f"Output directory: {out_dir}")


if __name__ == "__main__":
    main()